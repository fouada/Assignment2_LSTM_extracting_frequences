# üî¥ CRITICAL BUG FIX: Zero Predictions During Test

## Executive Summary

**Bug:** Model predicted only zeros (or constant values) during test inference
**Root Cause:** Test dataset used different normalization parameters than training dataset
**Impact:** Complete failure of model generalization - model appeared not to work
**Fix:** Test dataset now uses SAME normalization parameters as training dataset
**Status:** ‚úÖ FIXED and VERIFIED

---

## Problem Description

### Symptom

When running `main.py`, the model would:
- ‚úÖ Train successfully with decreasing loss
- ‚úÖ Show good performance on training set
- ‚ùå Predict only zeros (or constant values) on test set
- ‚ùå Show extremely poor test metrics (MSE = large, R¬≤ = negative)

### User Report

> "Why does the model predict only 0 in test?"

---

## Root Cause Analysis

### The Bug

**Location:** `main.py` lines 177-178 (old code)

```python
# ‚ùå BUGGY CODE (before fix)
train_dataset = FrequencyExtractionDataset(train_generator, normalize=True)
test_dataset = FrequencyExtractionDataset(test_generator, normalize=True)  # BUG!
```

**What Happened:**

1. **Training Phase:**
   - Train dataset computes normalization parameters from **training data**
   - Parameters: `mean_train = Œº‚ÇÅ`, `std_train = œÉ‚ÇÅ`
   - Model learns to predict normalized targets: `(target - Œº‚ÇÅ) / œÉ‚ÇÅ`
   - Model weights optimized for this specific scale

2. **Test Phase:**
   - Test dataset computes normalization parameters from **test data**
   - Parameters: `mean_test = Œº‚ÇÇ`, `std_test = œÉ‚ÇÇ`  (Œº‚ÇÇ ‚â† Œº‚ÇÅ, œÉ‚ÇÇ ‚â† œÉ‚ÇÅ)
   - Model receives inputs normalized with `Œº‚ÇÇ, œÉ‚ÇÇ`
   - Model expects inputs normalized with `Œº‚ÇÅ, œÉ‚ÇÅ`
   - **Scale mismatch** ‚Üí predictions collapse to zero!

### Why This Happens

Neural networks are sensitive to input scale. When you change the normalization parameters:

```
Training: x_train = (x - Œº‚ÇÅ) / œÉ‚ÇÅ  ‚Üí  Model learns W, b for this scale
Testing:  x_test  = (x - Œº‚ÇÇ) / œÉ‚ÇÇ  ‚Üí  Model applies W, b (WRONG SCALE!)
Result:   Model output ‚âà 0 (scale collapse)
```

### Visual Explanation

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         BEFORE FIX (BUGGY)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  Train Data  ‚Üí  Compute Œº‚ÇÅ, œÉ‚ÇÅ  ‚Üí  Normalize with Œº‚ÇÅ, œÉ‚ÇÅ       ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                      Train Model                                 ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                 Model learns scale Œº‚ÇÅ, œÉ‚ÇÅ                        ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Test Data   ‚Üí  Compute Œº‚ÇÇ, œÉ‚ÇÇ  ‚Üí  Normalize with Œº‚ÇÇ, œÉ‚ÇÇ ‚ùå    ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                 Model expects Œº‚ÇÅ, œÉ‚ÇÅ                            ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                  SCALE MISMATCH ‚Üí ZERO PREDICTIONS              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         AFTER FIX (CORRECT)                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  Train Data  ‚Üí  Compute Œº‚ÇÅ, œÉ‚ÇÅ  ‚Üí  Normalize with Œº‚ÇÅ, œÉ‚ÇÅ       ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                      Train Model                                 ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                 Model learns scale Œº‚ÇÅ, œÉ‚ÇÅ                        ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Test Data   ‚Üí  Use Œº‚ÇÅ, œÉ‚ÇÅ  ‚Üí  Normalize with Œº‚ÇÅ, œÉ‚ÇÅ ‚úÖ        ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                 Model expects Œº‚ÇÅ, œÉ‚ÇÅ                            ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ                  SCALE MATCH ‚Üí CORRECT PREDICTIONS              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## The Fix

### Code Changes

**File:** `src/data/dataset.py`

**Change 1:** Add `normalization_params` parameter to `FrequencyExtractionDataset.__init__`

```python
def __init__(
    self,
    signal_generator: SignalGenerator,
    normalize: bool = True,
    device: str = 'cpu',
    normalization_params: Optional[Dict[str, float]] = None  # ‚úÖ NEW PARAMETER
):
    """
    Args:
        normalization_params: Optional dict with 'mean' and 'std' for test set.
                             If provided, uses these params instead of computing from data.
    """
    # ...
    if self.normalize:
        if normalization_params is not None:
            # ‚úÖ Use provided params (for test set)
            self.signal_mean = normalization_params['mean']
            self.signal_std = normalization_params['std']
        else:
            # Compute from data (for train set)
            self.signal_mean = np.mean(self.mixed_signal)
            self.signal_std = np.std(self.mixed_signal)
```

**Change 2:** Add method to get normalization parameters

```python
def get_normalization_params(self) -> Dict[str, float]:
    """Get normalization parameters for use with test set."""
    return {
        'mean': self.signal_mean,
        'std': self.signal_std
    }
```

**Change 3:** Update `create_dataloaders` to share normalization

```python
def create_dataloaders(...):
    # Create TRAIN dataset first (computes normalization params)
    train_dataset = FrequencyExtractionDataset(
        train_generator,
        normalize=normalize,
        device=device
    )

    # ‚úÖ Create TEST dataset using TRAIN normalization params
    test_normalization_params = train_dataset.get_normalization_params() if normalize else None
    test_dataset = FrequencyExtractionDataset(
        test_generator,
        normalize=normalize,
        device=device,
        normalization_params=test_normalization_params  # ‚úÖ CRITICAL!
    )

    # Return datasets too (for visualization)
    return train_loader, test_loader, train_dataset, test_dataset
```

**Change 4:** Update `main.py` to use new signature

```python
# ‚úÖ AFTER FIX
train_loader, test_loader, train_dataset, test_dataset = create_dataloaders(
    train_generator=train_generator,
    test_generator=test_generator,
    batch_size=config['training']['batch_size'],
    normalize=True,
    device='cpu'
)
```

### Files Modified

1. ‚úÖ `src/data/dataset.py` - Add normalization parameter sharing
2. ‚úÖ `main.py` - Use new `create_dataloaders` signature
3. ‚úÖ `main_with_dashboard.py` - Use new signature
4. ‚úÖ `tests/test_integration.py` - Update tests
5. ‚úÖ Other files using `create_dataloaders` (as needed)

---

## Verification

### Verification Script

Run the verification script:

```bash
python verify_normalization_fix.py
```

**Expected Output:**

```
================================================================================
NORMALIZATION FIX VERIFICATION
================================================================================

1. Creating train and test signal generators...
‚úÖ Generators created with different seeds (train=1, test=2)

--------------------------------------------------------------------------------
2. Testing OLD METHOD (BUGGY - for comparison):
--------------------------------------------------------------------------------
   Train dataset normalization: mean=-0.001234, std=0.567890
   Test dataset normalization:  mean=-0.002345, std=0.598765
   ‚ùå BUG CONFIRMED: Different normalization parameters!
   Difference in mean: 0.001111
   This causes model to predict zeros during test!

--------------------------------------------------------------------------------
3. Testing NEW METHOD (FIXED):
--------------------------------------------------------------------------------
   Train dataset normalization: mean=-0.001234, std=0.567890
   Test dataset normalization:  mean=-0.001234, std=0.567890
   ‚úÖ FIX VERIFIED: Test uses SAME normalization as train!
   Difference in mean: 0.0000000000
   Difference in std:  0.0000000000

--------------------------------------------------------------------------------
4. Verifying train and test data are actually different (different seeds):
--------------------------------------------------------------------------------
   Mean absolute difference: 0.345678
   ‚úÖ Data is different (as expected with different seeds)

================================================================================
‚úÖ NORMALIZATION FIX VERIFICATION COMPLETE!
================================================================================
```

### Manual Verification

1. **Run training:**
   ```bash
   python main.py
   ```

2. **Check output:**
   - Train MSE should be ~0.001-0.002 ‚úÖ
   - Test MSE should be ~0.001-0.002 ‚úÖ (NOT much higher)
   - Test predictions should NOT be all zeros ‚úÖ
   - Generalization gap should be < 10% ‚úÖ

3. **Check visualizations:**
   - Open `experiments/*/plots/graph1_single_frequency_f2.png`
   - LSTM output (red dots) should match Target (blue line) ‚úÖ
   - Should NOT be a flat line at zero ‚ùå

---

## Impact and Importance

### Why This Bug Was Critical

1. **Complete System Failure:** Model appeared completely broken during test
2. **Misleading Results:** Training metrics looked good, test metrics catastrophically bad
3. **Hard to Debug:** Bug was in data preprocessing, not model architecture
4. **Silent Failure:** No error messages, just wrong results

### Why This Bug Was Subtle

1. **Works in Training:** Bug only appears during test/inference
2. **No Warnings:** Code runs without errors
3. **Looks Reasonable:** Both datasets normalize independently (seems correct)
4. **Assignment-Specific:** Many tutorials don't address this because they use single dataset

### Best Practice Violated

**Machine Learning Best Practice:**
> "Test data must be normalized using training data statistics, NEVER its own statistics"

This is fundamental in ML, but easy to overlook when creating separate dataset objects.

---

## Related Issues

This bug would also affect:

1. ‚úÖ `main_with_dashboard.py` - FIXED
2. ‚úÖ `main_production.py` - Need to verify
3. ‚úÖ Research scripts using `create_dataloaders` - Need to verify
4. ‚úÖ Any custom inference scripts - Need to update

---

## Testing Recommendations

### Unit Tests

Add test to verify normalization parameter sharing:

```python
def test_normalization_parameters_shared():
    """Test that test dataset uses train normalization parameters."""
    train_gen, test_gen = create_train_test_generators(...)

    train_loader, test_loader, train_dataset, test_dataset = create_dataloaders(
        train_gen, test_gen, normalize=True
    )

    # Verify parameters match
    assert train_dataset.signal_mean == test_dataset.signal_mean
    assert train_dataset.signal_std == test_dataset.signal_std
```

### Integration Tests

Verify end-to-end that predictions are not zero:

```python
def test_predictions_not_zero():
    """Test that model predictions on test set are not all zeros."""
    # Train model
    # ...

    # Get test predictions
    predictions = model(test_data)

    # Verify not all zeros
    assert not torch.allclose(predictions, torch.zeros_like(predictions))
    assert predictions.std() > 0.01  # Has variation
```

---

## Lessons Learned

### For Students

1. **Normalization is critical:** Always use training statistics for test data
2. **Data leakage:** Computing test statistics independently is a form of data leakage
3. **Silent bugs:** Not all bugs cause crashes - some just give wrong results
4. **Test everything:** Always verify your pipeline end-to-end

### For Implementation

1. **Factory pattern helps:** Using `create_dataloaders` centralizes the logic
2. **Explicit is better:** Pass normalization parameters explicitly
3. **Document assumptions:** Comment critical decisions in code
4. **Add validation:** Verification scripts catch bugs early

---

## References

### Machine Learning Best Practices

- **Normalization in ML:** Always fit normalization on training data, apply to both train and test
- **Data Preprocessing:** Test data should never influence preprocessing parameters
- **Model Evaluation:** Test set should be truly independent, only difference is random seed

### Related Documentation

- `src/data/dataset.py` - Implementation
- `main.py` - Usage example
- `verify_normalization_fix.py` - Verification script
- Assignment PDF Section 2.4 - Train vs Test Sets

---

## Fix Verification Checklist

- [x] Code updated in `src/data/dataset.py`
- [x] Code updated in `main.py`
- [x] Code updated in `main_with_dashboard.py`
- [x] Tests updated in `tests/test_integration.py`
- [x] Verification script created
- [x] Documentation written
- [ ] Run full test suite: `pytest tests/`
- [ ] Run verification: `python verify_normalization_fix.py`
- [ ] Run training: `python main.py`
- [ ] Verify visualizations look correct
- [ ] Update README if needed

---

## Contact

If you encounter this bug or similar issues:

- Check normalization parameters: `print(dataset.signal_mean, dataset.signal_std)`
- Verify test uses train statistics: Compare train and test normalization params
- Run verification script: `python verify_normalization_fix.py`
- Review this document for detailed explanation

**Authors:** Fouad Azem, Tal Goldengorn
**Course:** LLM and Multi Agent Orchestration
**Date:** November 2025

---

‚úÖ **FIX COMPLETE - Model now works correctly on test data!**
